{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 18:43:40.459952: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# ML Tools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# To prepare data\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Train Tools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# other settings\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = pd.read_csv('data/f_m_names.csv')\n",
    "df = shuffle(mdata)\n",
    "df = df.dropna()\n",
    "train = df[:5000]\n",
    "test = df[5000:6264]\n",
    "\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>Исаев Сергей Константинович</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>Голикова Евгения Фёдоровна</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>Титова Злата Егоровна</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Котов Александр Михайлович</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Попов Ярослав Алексеевич</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  label\n",
       "2457  Исаев Сергей Константинович      1\n",
       "4346   Голикова Евгения Фёдоровна      0\n",
       "3600        Титова Злата Егоровна      0\n",
       "495    Котов Александр Михайлович      1\n",
       "731      Попов Ярослав Алексеевич      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data from punctuation marks and convert to lowercase\n",
    "\n",
    "stopwords_rus = set(stopwords.words(\"russian\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = re.sub(\"[^а-я]\", \" \", text)\n",
    "    words = [word for word in text.split() if word not in stopwords_rus]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "clean_train_reviews = train['text'].map(clean_text)\n",
    "clean_test_reviews = test['text'].map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "MAX_SEQUENCE_LENGTH_NAMES = 36\n",
    "vocab_size_names = 5793\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(clean_train_reviews + clean_train_reviews)\n",
    "\n",
    "text_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n",
    "train_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH_NAMES, padding='post')\n",
    "\n",
    "text_sequences = tokenizer.texts_to_sequences(clean_test_reviews)\n",
    "test_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH_NAMES, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size_names, 16, input_length=MAX_SEQUENCE_LENGTH_NAMES))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.005)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(8, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 36, 16)            92688     \n",
      "                                                                 \n",
      " global_average_pooling1d_3   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,129\n",
      "Trainable params: 96,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_name()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = train_inputs[:4000]\n",
    "X_train = train_inputs[4000:]\n",
    "\n",
    "y_val = np.array(train['label'].iloc[:4000])\n",
    "y_train = np.array(train['label'].iloc[4000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "2/2 [==============================] - 0s 336ms/step - loss: 0.7340 - acc: 0.5150 - val_loss: 0.7325 - val_acc: 0.6750\n",
      "Epoch 2/35\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7283 - acc: 0.8770 - val_loss: 0.7266 - val_acc: 0.9862\n",
      "Epoch 3/35\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7222 - acc: 0.9990 - val_loss: 0.7227 - val_acc: 0.8062\n",
      "Epoch 4/35\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7176 - acc: 0.9240 - val_loss: 0.7184 - val_acc: 0.8435\n",
      "Epoch 5/35\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7127 - acc: 0.9860 - val_loss: 0.7137 - val_acc: 0.9235\n",
      "Epoch 6/35\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7074 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.9545\n",
      "Epoch 7/35\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7013 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.9805\n",
      "Epoch 8/35\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6947 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.9925\n",
      "Epoch 9/35\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6877 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.9942\n",
      "Epoch 10/35\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6802 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 0.9942\n",
      "Epoch 11/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6719 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.9945\n",
      "Epoch 12/35\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6630 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.9948\n",
      "Epoch 13/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6532 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.9992\n",
      "Epoch 14/35\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6423 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.9975\n",
      "Epoch 15/35\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6303 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 0.9998\n",
      "Epoch 16/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6173 - acc: 1.0000 - val_loss: 0.6214 - val_acc: 0.9992\n",
      "Epoch 17/35\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6032 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.9998\n",
      "Epoch 18/35\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5880 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.9992\n",
      "Epoch 19/35\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5725 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 1.0000\n",
      "Epoch 20/35\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5561 - acc: 1.0000 - val_loss: 0.5638 - val_acc: 0.9998\n",
      "Epoch 21/35\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5385 - acc: 1.0000 - val_loss: 0.5465 - val_acc: 1.0000\n",
      "Epoch 22/35\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5199 - acc: 1.0000 - val_loss: 0.5290 - val_acc: 1.0000\n",
      "Epoch 23/35\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5006 - acc: 1.0000 - val_loss: 0.5103 - val_acc: 1.0000\n",
      "Epoch 24/35\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4805 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 1.0000\n",
      "Epoch 25/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4598 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 1.0000\n",
      "Epoch 26/35\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4386 - acc: 1.0000 - val_loss: 0.4521 - val_acc: 1.0000\n",
      "Epoch 27/35\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4170 - acc: 1.0000 - val_loss: 0.4322 - val_acc: 1.0000\n",
      "Epoch 28/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3952 - acc: 1.0000 - val_loss: 0.4113 - val_acc: 1.0000\n",
      "Epoch 29/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3738 - acc: 1.0000 - val_loss: 0.3911 - val_acc: 1.0000\n",
      "Epoch 30/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3520 - acc: 1.0000 - val_loss: 0.3702 - val_acc: 1.0000\n",
      "Epoch 31/35\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3307 - acc: 1.0000 - val_loss: 0.3500 - val_acc: 1.0000\n",
      "Epoch 32/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3097 - acc: 1.0000 - val_loss: 0.3307 - val_acc: 1.0000\n",
      "Epoch 33/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2898 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 1.0000\n",
      "Epoch 34/35\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2706 - acc: 1.0000 - val_loss: 0.2932 - val_acc: 1.0000\n",
      "Epoch 35/35\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2523 - acc: 1.0000 - val_loss: 0.2755 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"pretrained_models/training_names/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=35,\n",
    "                    batch_size=512,\n",
    "                    validation_data=[X_val, y_val],\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x145170e80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"pretrained_models/training_names/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 939us/step\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predictions = np.rint(model.predict(test_inputs)).astype('int32').squeeze()\n",
    "\n",
    "cfm = confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(cfm, annot=True, fmt=\"d\", cbar=False)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales",
   "language": "python",
   "name": "sales"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
