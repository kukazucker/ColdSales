{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff791731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 19:06:58.178291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# to input data and graphs\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "# preprocessing\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# train tools\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# another settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e077856",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcc158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MORNING</th>\n",
       "      <th>DAY</th>\n",
       "      <th>EVENING</th>\n",
       "      <th>NIGHT</th>\n",
       "      <th>FIRST TWEET</th>\n",
       "      <th>SECOND TWEET</th>\n",
       "      <th>THIRD TWEET</th>\n",
       "      <th>FOURTH TWEET</th>\n",
       "      <th>PURCHASE AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Жданова Мария Ивановна</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q: Вот я Вася  как я могла не правильно написа...</td>\n",
       "      <td>Еду домой в автобусе =\"( мочевой пузырь ща лоп...</td>\n",
       "      <td>@DmitryMalikov Радость нежность и тоска чувств...</td>\n",
       "      <td>RT @RaccoonMr: МЕНЬШЕ ЧЕМ ЧЕРЕЗ 2 НЕДЕЛИ КАНИК...</td>\n",
       "      <td>17209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Никитин Георгий Родионович</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Будем надеяться на хорошую погоду на выходных ...</td>\n",
       "      <td>869844/1 Я ее просто распихать по шкафам не ус...</td>\n",
       "      <td>Распродажа сумок для ноутбуков ))) Все по 1000...</td>\n",
       "      <td>@galyonkin КАК?! Я просто хочу знать учитывая ...</td>\n",
       "      <td>73248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Исаева Анна Георгиевна</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>это 5 хоть и баян) \"@root_sashok: :D http://t....</td>\n",
       "      <td>Новогодняя аудио подборочка) Забираем на стену...</td>\n",
       "      <td>@irina33371 ахахахх я заметила: отмычки перчат...</td>\n",
       "      <td>Что делать в случае \"никто-тебя-не-любит\"? ДЕЛ...</td>\n",
       "      <td>24312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сидоров Олег Алексеевич</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@_StalArt_ очень верное и мудрое решениетак ск...</td>\n",
       "      <td>@DyagilevaNastya @3DG_rock7 любовный треугольн...</td>\n",
       "      <td>@controlflow Когда упускаю-то? в #1? Это ты пр...</td>\n",
       "      <td>RT @4ayanmusiq: В декабре я снова посещу Казан...</td>\n",
       "      <td>71999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Николаева Юлия Матвеевна</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @ksana_semenova: эти чихающие детки в школе...</td>\n",
       "      <td>#ХочуПровестиНовогоднююНочьВместеС @coldiumtea...</td>\n",
       "      <td>Прогуливаю английский чтобы пойти на факультат...</td>\n",
       "      <td>@pani_walewska @rubis32 @maxbryansk ждете сигн...</td>\n",
       "      <td>35056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         NAME  AGE  MORNING  DAY  EVENING  NIGHT  \\\n",
       "0      Жданова Мария Ивановна   22        1    1        1      1   \n",
       "1  Никитин Георгий Родионович   24        1    1        0      0   \n",
       "2      Исаева Анна Георгиевна   24        1    1        1      1   \n",
       "3     Сидоров Олег Алексеевич   21        1    1        0      0   \n",
       "4    Николаева Юлия Матвеевна   20        0    0        1      0   \n",
       "\n",
       "                                         FIRST TWEET  \\\n",
       "0  Q: Вот я Вася  как я могла не правильно написа...   \n",
       "1  Будем надеяться на хорошую погоду на выходных ...   \n",
       "2  это 5 хоть и баян) \"@root_sashok: :D http://t....   \n",
       "3  @_StalArt_ очень верное и мудрое решениетак ск...   \n",
       "4  RT @ksana_semenova: эти чихающие детки в школе...   \n",
       "\n",
       "                                        SECOND TWEET  \\\n",
       "0  Еду домой в автобусе =\"( мочевой пузырь ща лоп...   \n",
       "1  869844/1 Я ее просто распихать по шкафам не ус...   \n",
       "2  Новогодняя аудио подборочка) Забираем на стену...   \n",
       "3  @DyagilevaNastya @3DG_rock7 любовный треугольн...   \n",
       "4  #ХочуПровестиНовогоднююНочьВместеС @coldiumtea...   \n",
       "\n",
       "                                         THIRD TWEET  \\\n",
       "0  @DmitryMalikov Радость нежность и тоска чувств...   \n",
       "1  Распродажа сумок для ноутбуков ))) Все по 1000...   \n",
       "2  @irina33371 ахахахх я заметила: отмычки перчат...   \n",
       "3  @controlflow Когда упускаю-то? в #1? Это ты пр...   \n",
       "4  Прогуливаю английский чтобы пойти на факультат...   \n",
       "\n",
       "                                        FOURTH TWEET  PURCHASE AMOUNT  \n",
       "0  RT @RaccoonMr: МЕНЬШЕ ЧЕМ ЧЕРЕЗ 2 НЕДЕЛИ КАНИК...            17209  \n",
       "1  @galyonkin КАК?! Я просто хочу знать учитывая ...            73248  \n",
       "2  Что делать в случае \"никто-тебя-не-любит\"? ДЕЛ...            24312  \n",
       "3  RT @4ayanmusiq: В декабре я снова посещу Казан...            71999  \n",
       "4  @pani_walewska @rubis32 @maxbryansk ждете сигн...            35056  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/sales.csv', index_col=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03232e37",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53615b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shuffle(data)\n",
    "y = X.pop('PURCHASE AMOUNT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d2a63",
   "metadata": {},
   "source": [
    "## 3. Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e1a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 140\n",
    "MAX_SEQUENCE_LENGTH_NAMES = 36\n",
    "\n",
    "vocab_size = 152836\n",
    "vocab_size_names = 5793\n",
    "\n",
    "def model_name():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size_names, 16, input_length=MAX_SEQUENCE_LENGTH_NAMES))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.005)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(8, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    return model\n",
    "\n",
    "def model_tweet():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size, 16, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.005)))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(8, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    return model\n",
    "\n",
    "stopwords_rus = set(stopwords.words(\"russian\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = re.sub(\"[^а-я]\", \" \", text)\n",
    "    words = [word for word in text.split() if word not in stopwords_rus]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "# loading\n",
    "with open('pretrained_models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "with open('pretrained_models/tokenizer_names.pickle', 'rb') as handle:\n",
    "    tokenizer_names = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1add6c",
   "metadata": {},
   "source": [
    "## 4. Custom Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041d4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED for reproducible result\n",
    "from tqdm import tqdm\n",
    "SEED = 101\n",
    "mod_names_path = \"pretrained_models/training_names/cp.ckpt\"\n",
    "mod_tweet_path = \"pretrained_models/training_tweets/cp.ckpt\"\n",
    "\n",
    "class CustomRegressor():\n",
    "    \n",
    "    def __init__(self, n_estimators=None, min_weight_fraction_leaf=None, max_leaf_nodes=None):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "    \n",
    "    def _clearText_(self, X, columns):\n",
    "        \n",
    "        for column in columns:\n",
    "            X[column] = X[column].map(clean_text)\n",
    "        return X\n",
    "    \n",
    "    def _predProf_(self, X):\n",
    "        \n",
    "        data = X[['MORNING', 'DAY', 'EVENING', 'NIGHT']]\n",
    "        clf = load('pretrained_models/prof_clf.joblib') \n",
    "        predicted_profs = clf.predict(data)\n",
    "        X['PROFESSION'] = predicted_profs\n",
    "        return X\n",
    "    \n",
    "    def _predCondition_(self, X):\n",
    "        \n",
    "        model = model_tweet()\n",
    "        model.load_weights(mod_tweet_path)\n",
    "        tweets = ['FIRST TWEET', 'SECOND TWEET', 'THIRD TWEET', 'FOURTH TWEET']\n",
    "        condition = pd.DataFrame(0, index=np.arange(len(X)), columns={0: 'CONDITION'})\n",
    "        for tweet in tweets:\n",
    "            text_sequences = tokenizer.texts_to_sequences(X[tweet])\n",
    "            tweet_texts = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "            predicted_cond = np.rint(model.predict(tweet_texts)).astype('int32')\n",
    "            condition += predicted_cond\n",
    "        condition = condition.replace(0, 1)\n",
    "        X['CONDITION'] = 0\n",
    "        for i, num in enumerate(condition):\n",
    "            X['CONDITION'].iloc[i] = condition.iloc[i]\n",
    "        return X\n",
    "    \n",
    "    def _predGender_(self, X):\n",
    "        \n",
    "        data = X['NAME']\n",
    "        model = model_name()\n",
    "        model.load_weights(mod_names_path)\n",
    "        text_sequences = tokenizer_names.texts_to_sequences(data)\n",
    "        names = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH_NAMES, padding='post')\n",
    "        predicted_genders = np.rint(model.predict(names)).astype('int32')\n",
    "        X['GENDER'] = predicted_genders\n",
    "        return X\n",
    "    \n",
    "    def _prepare_(self, X):\n",
    "        \n",
    "        X1 = self._clearText_(X, ['FIRST TWEET', 'SECOND TWEET', 'THIRD TWEET', 'FOURTH TWEET', 'NAME'])\n",
    "        X2 = self._predProf_(X1)\n",
    "        X3 = self._predCondition_(X2)\n",
    "        X4 = self._predGender_(X3)\n",
    "        X5 = X4.drop(['NAME', 'MORNING', 'DAY', 'EVENING', 'NIGHT', 'FIRST TWEET', 'SECOND TWEET', 'THIRD TWEET', 'FOURTH TWEET'], axis=1)\n",
    "        return X5\n",
    "        \n",
    "    def _estimator_(self, X, y):\n",
    "        warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "            \n",
    "        GausProcess = make_pipeline(\n",
    "            TransformedTargetRegressor(\n",
    "                regressor = GaussianProcessRegressor(random_state=SEED),\n",
    "                func=np.log1p,\n",
    "                inverse_func=np.expm1)\n",
    "        )\n",
    "            \n",
    "        CatBoost = make_pipeline(\n",
    "            TransformedTargetRegressor(\n",
    "                regressor = CatBoostRegressor(random_state=SEED, verbose=0),\n",
    "                func=np.log1p,\n",
    "                inverse_func=np.expm1)\n",
    "        )\n",
    "            \n",
    "        RandForest = make_pipeline(\n",
    "            TransformedTargetRegressor(\n",
    "                regressor = RandomForestRegressor(max_leaf_nodes=60, max_depth=9, random_state=SEED),\n",
    "                func=np.log1p,\n",
    "                inverse_func=np.expm1)\n",
    "        )\n",
    "        \n",
    "        estimators = [\n",
    "            ('GaussProcess', GausProcess),\n",
    "            ('CatBoost', CatBoost),\n",
    "            (\"RandForest\", RandForest)\n",
    "        ]\n",
    "            \n",
    "        model = VotingRegressor(estimators)\n",
    "            \n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        print(\"Fit stage...\")\n",
    "        X = self._prepare_(X)\n",
    "        self.estimators_ = []\n",
    "        estimator_ = self._estimator_(X, y)\n",
    "        self.estimators_.append(estimator_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        print(\"Prediction stage...\")\n",
    "        X = self._prepare_(X)\n",
    "        y_pred = []\n",
    "        for est in tqdm(self.estimators_):\n",
    "            y_pred_ = est.predict(X)\n",
    "            y_pred.append(y_pred_)\n",
    "            \n",
    "        return np.stack(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ac062",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a96f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984dd375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit stage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 19:07:02.517174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 710us/step\n",
      "126/126 [==============================] - 0s 704us/step\n",
      "126/126 [==============================] - 0s 801us/step\n",
      "126/126 [==============================] - 0s 707us/step\n",
      "126/126 [==============================] - 0s 904us/step\n",
      "Prediction stage...\n",
      "62/62 [==============================] - 0s 786us/step\n",
      "62/62 [==============================] - 0s 783us/step\n",
      "62/62 [==============================] - 0s 740us/step\n",
      "62/62 [==============================] - 0s 718us/step\n",
      "62/62 [==============================] - 0s 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model = CustomRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326d6f4",
   "metadata": {},
   "source": [
    "## 6. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b3fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction stage...\n",
      "62/62 [==============================] - 0s 810us/step\n",
      "62/62 [==============================] - 0s 763us/step\n",
      "62/62 [==============================] - 0s 672us/step\n",
      "62/62 [==============================] - 0s 722us/step\n",
      "62/62 [==============================] - 0s 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = predictions.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4890f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 10029.05\n",
      "Mean squared error = 185528691.13\n",
      "Median absolute error = 7902.5\n",
      "Explain variance score = 0.86\n",
      "R2 score = 0.86\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "from joblib import load\n",
    "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test, predictions), 2)) \n",
    "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, predictions), 2)) \n",
    "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test, predictions), 2)) \n",
    "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test, predictions), 2)) \n",
    "print(\"R2 score =\", round(sm.r2_score(y_test, predictions), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales",
   "language": "python",
   "name": "sales"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
